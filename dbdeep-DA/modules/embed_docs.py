import os
import logging
from uuid import uuid4
from dotenv import load_dotenv

from config.setup import init_pinecone
from llm.gemini import GeminiEmbeddingViaGMS

from pinecone import Pinecone, ServerlessSpec
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_pinecone import PineconeVectorStore 
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document

load_dotenv()

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logging.info("ğŸ“¦ ë¬¸ì„œ ì„ë² ë”© ë° Pinecone ì—…ë¡œë“œ ì‹œì‘")

# ----------------------------
#  Pinecone ì´ˆê¸°í™”
# ----------------------------

init_pinecone()

index_name = "schema-index" # "schema-index-google", "schema-index"
pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"])
if index_name not in pc.list_indexes().names():
    dimension = 1024 if index_name=="schema-index" else 768
    pc_index = pc.create_index(
        name=index_name,
        dimension=dimension,  # ëª¨ë¸ì— ë§ëŠ” ì°¨ì›ìœ¼ë¡œ ì„¤ì • (ì˜ˆ: 384, 768, 1536 ë“±)
        metric="cosine",
        spec=ServerlessSpec(
            cloud="gcp",
            region=os.environ.get("PINECONE_ENV", "us-east-1")
        )
    )
    
index = pc.Index(index_name)
logging.info("ğŸ“¦ Pinecone ì´ˆê¸°í™”")

# ----------------------------
#  ë¬¸ì„œ ë¡œë“œ ë° ì¶œì²˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
# ----------------------------
root_dir = "assets/RAG_docs"
# text_files = ["1.card_members.txt", "2.card_credit.txt", "3.card_sales.txt"]  # ë‹¤ì¤‘ ë¬¸ì„œ ëª©ë¡
text_files = ["hr_dataset_description.txt", "business_term.txt", "bigquery_sql.txt"]

document_types = {
    "hr_dataset_description.txt": "schema_description",
    "business_term.txt": "business_term",
    "bigquery_sql.txt": "sql_guide"
}

docs = []

# for file_path in text_files:
#     logging.info(f"ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘: {file_path}")
#     loader = TextLoader(f"{root_dir}/{file_path}", encoding="utf-8")
#     loaded_docs = loader.load()
#     for doc in loaded_docs:
#         doc.metadata["source"] = os.path.basename(file_path)
#     docs.extend(loaded_docs)

for filename, doc_type in document_types.items():
    filepath = os.path.join(root_dir, filename)
    logging.info(f"ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘: {filename}")
    loader = TextLoader(filepath, encoding="utf-8")
    loaded_docs = loader.load()
    for doc in loaded_docs:
        doc.metadata["source"] = filename
        doc.metadata["type"] = doc_type
    docs.extend(loaded_docs)

# ----------------------------
#  ë¬¸ì„œ ë¶„í•  (chunk ë‹¨ìœ„)
# ----------------------------
logging.info("âœ‚ï¸ ë¬¸ì„œ chunk ë¶„í•  ì¤‘...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
splits = text_splitter.split_documents(docs)

logging.info(f"ğŸ”¢ ì´ split ë¬¸ì„œ ìˆ˜: {len(splits)}")


# ----------------------------
#  KURE-v1 ì„ë² ë”© (Hugging Face ëª¨ë¸ ì‚¬ìš©)
# ----------------------------
logging.info("ğŸ” ì„ë² ë”© ìƒì„± ì¤‘...")

embedding = HuggingFaceEmbeddings(
    model_name="nlpai-lab/KURE-v1",
    model_kwargs={"device": "cpu"},  # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ "cuda"
    encode_kwargs={"normalize_embeddings": True}
)

# embedding = GeminiEmbeddingViaGMS(api_key=os.environ["GEMINI_API_KEY"])


# ----------------------------
#  Pineconeì— ì—…ë¡œë“œ
# ----------------------------
logging.info("ğŸ“¡ Pineconeì— ë²¡í„° ì—…ë¡œë“œ ì¤‘...")

documents = [
    Document(page_content=doc.page_content, metadata=doc.metadata)
    for doc in splits
]
ids = [str(uuid4()) for _ in documents]

vectorstore = PineconeVectorStore(index=index, embedding=embedding)
vectorstore.add_documents(documents=documents, ids=ids)

logging.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ: ë¬¸ì„œ ì„ë² ë”© â†’ Pinecone ì—…ë¡œë“œ ì™„ë£Œ")

